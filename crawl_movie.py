import requests
from bs4 import BeautifulSoup, Tag
import csv

URL = "https://vi.wikipedia.org/wiki/Danh_s%C3%A1ch_phim_%C4%91i%E1%BB%87n_%E1%BA%A3nh_Vi%E1%BB%87t_Nam#Th%E1%BA%ADp_ni%C3%AAn_2020"
TARGET_ID = "Th·∫≠p_ni√™n_2020"

headers = {"User-Agent": "Mozilla/5.0"}
res = requests.get(URL, headers=headers, timeout=30)
res.raise_for_status()
res.encoding = "utf-8"
soup = BeautifulSoup(res.text, "lxml")

# B1: t√¨m <h3 id="Th·∫≠p_ni√™n_2020">
anchor = soup.find(id=TARGET_ID)
h3 = anchor if (anchor and anchor.name == "h3") else (anchor.find_parent("h3") if anchor else None)
if not h3:
    raise RuntimeError("Kh√¥ng t√¨m th·∫•y <h3 id='Th·∫≠p_ni√™n_2020'>")

# B2: cha tr·ª±c ti·∫øp c·ªßa h3
parent = h3.parent

# B3: t√¨m b·∫£ng wikitable c√πng c·∫•p v·ªõi cha
table = None
for sib in parent.next_siblings:
    if isinstance(sib, Tag) and sib.name == "table" and "wikitable" in (sib.get("class") or []):
        table = sib
        break

if not table:
    raise RuntimeError("Kh√¥ng t√¨m th·∫•y table.wikitable sau heading")

print("ƒê√£ t√¨m th·∫•y table.wikitable")

# B4: l·∫•y header (h√†ng th)
header_row = table.find("tr")
header = [th.get_text(strip=True) for th in header_row.find_all("th")]
print("Header:", header)

# B5: l·∫•y data
rows = []
for tr in table.find_all("tr")[1:]:  # b·ªè h√†ng header
    cols = [td.get_text(strip=True) for td in tr.find_all("td")]
    if cols:
        rows.append(cols)

print(f"Thu ƒë∆∞·ª£c {len(rows)} d√≤ng d·ªØ li·ªáu")

# B6: ghi ra CSV
with open("movie.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    if header:  # ch·ªâ ghi n·∫øu header c√≥ d·ªØ li·ªáu
        writer.writerow(header)
    writer.writerows(rows)

print("üíæ ƒê√£ l∆∞u d·ªØ li·ªáu v√†o movie.csv")